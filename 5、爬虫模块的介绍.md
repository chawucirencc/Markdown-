模块的介绍：

---

 Python2 里常用```urllib``` 和 ```urllib2``` ，Python3 里常用 ```reuquests``` 模块。

logging模块可以将标准输出到日志文件保存起来。

### 1、请求模块requests： ###

参考文档： https://requests.kennethreitz.org//zh_CN/latest/user/quickstart.html 

```reuquests``` 应该算是对 ```urllib``` 和 ```urllib2 ``` 的扩展，使用起来更加方便，并且可以自动的把返回的信息进行解码。```get``` 请求用法：

通常会加上错误处理：

```python
url = "https://www.baidu.com/"
res = requests.get(url)
print(res.status_code)
res.encoding = 'utf-8'
print(res.text)
```

```post``` 请求用法：

```python
url = "XXXXXXXXXXXXXX"
data = {
    'key1':'value1',
    'key2':'value2'
}
res = requests.post(url, data)
print(res.status_code)
res.encoding = 'utf-8'
print(res.text)
```

在请求参数内添加```headers``` 参数，可以设置 IP 池和随机的 UA。

关于 Headers 中的一些信息：

*   Request URL：表示这个网页的请求地址。
*   Request Method：请求方法，大部分为 get 和 post 两种。
*   Status Code：状态码，正常的话会是200。
*   User-Agent：浏览器标识。
*   Cookies：登录信息的存放的地方。

### 2、网页解析模块： ###

##### `BeautifulSoup` #####

```BeautifulSoup``` 参考文档： https://beautifulsoup.readthedocs.io/zh_CN/v4.4.0/ 

从模块加载`BeautifulSoup`

```python
from bs4 import BeautifulSoup
soup = BeautifulSoup(html_doc, "html.parse") # 解析方法可以选择其他更高性能的lxml、
```

在 `BeautifulSoup` 中使用的是 CSS 选择器。关于选择器的具体可以看选择器 MD 文件。

待补充....

##### `lxml` #####

```python
from lxml import etree
page = etree.HTML(response.text) # 返回的page是一个节点(Element)，使用选择器选择节点中的数据。
result = page.xpath(".//div[@class='test']//p//text")
# result节点得到所有class="test"的div节点下p节点的所有文本。返回结果是个list。
```

上面是解析html的方法。

还有其他的一些用法。

##### `pyquery` #####

```python
from pyquery import PyQuery as pq
response = pq(a) # a为形参，可以为URL地址，可以为HTML文档，当a为URL地址的时候，会对地址发送请求，返回网页源代码。
# 基于CSS选择器。
response = pq(url="https://www.baidu.com/", encoding='utf-8')
print(response)
# 将网页源代码文本解析之后会变成<class 'pyquery.pyquery.PyQuery'>这个对象！然后使用CSS选择器进行信息提取！
```

一般最常使用的是`requests`进行请求，然后使用`BeautifulSoup`或者`lxml`对返回的文本进行解析！

##### 正则表达式 #####

正则表达式在格式化数据、提取数据和清洗数据等方面会有些作用。

替换字符串，使用正则表达式提取网页中的结构化数据！或者是从网页中提取的数据存在回车和换行的时候可以使用`sub`将其替换掉！

参考： https://www.cnblogs.com/hanmk/p/9143514.html 

爬虫框架可以参考另一份文件！

### 3、验证码识别 ###















