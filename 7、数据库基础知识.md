## 一、关系型数据库

MySQL为例：

MySQL中文文档：https://www.mysqlzh.com/

采用关系模式来组成数据库，其数据以行和列的形式存在，便于用户理解。行和列的形式称为表，一组表就组成了一个数据库。

按照数据结构来组织、存储和管理数据，实际上总共有三种模型：

*   层次模型
*   网状模型
*   关系模型

关系模型就是：指用二维表的形式表示实体和实体间联系的数据模型。关系模型中无论是实体还是实体间的联系都由单一的结构类型--关系来表示，在实际的关系数据库中也称作表。

实体：就数据库而言，实体往往是指某类事物的集合，可以是具体的人或事物，也可以是抽象的概念。实体之间的关系，一对一，一对多，多对多。

---

关于数据库的一些特征：

*   数据库：数据库是一些关联表的集合。
*   数据表：表示数据的矩阵，在一个数据库中有很多的表。
*   列：一列元素包含相同的数据类型。
*   行：（=元组）是一组相关的数据，比如一个用户的一些姓名，性别，年龄等等。
*   冗余：存储两倍数据，冗余降低了性能，但是提高了数据的安全性。
*   主键：主键是唯一的，一个数据表中只有一个主键。
*   外键：外键用于关联两个表。
*   复合键：将多个列作为一个索引键，一般用于符合索引。
*   索引：使用索引可以快速访问数据库中的特定信息，索引是对数据库表中一列或者多了的值进行排序的一种结构，类似于书记的目录。
*   参照完整性：参照的完整性要求关系中不允许引用不存在的实体。参照完整性和实体完整性是关系模型必须满足的完整性约束条件。目的是保证数据的一致性。

SQL事物：

参考：https://www.runoob.com/mysql/mysql-transaction.html

一般来讲，事物必须满足4个条件（ACID）：原子性（Atomicity，或称不可分割性）、一致性（Consistency）、隔离性（Isolation，又称独立性）、持久性（Durability）。

*   原子性：一个事物中的操作要么全部完成，要么全部不完成。不会结束在中间的某个环节，事物在执行过程中发生错误的话会被回滚到事物开始前的状态。
*   一致性：在事物开始前和事物结束后数据库的完整性没有被破坏、这表示着写入的资料必须完全符合所有的预设规则，这包含资料的精确度，串联性以及后续数据库可以自发性的完成预定的的工作。
*   隔离性：数据库允许多个并发事物同时对数据进行读写和修改的能力，隔离性可以防止多个事物并发执行是由于交叉执行而导致数据的不一致，事物的隔离分为不同级别，包括读未提交、读提交、可重复读、和串行化。
*   持久性：事物处理结束后，对数据的修改就是永久的，即使系统故障也不会丢失。

待补充......

### **SQL语句：**  ###

```mysql
case 
	when condition then
	when condition then
# 类似于if...elif...else...
```

##### 连接表： #####

```sql
SELECT
	field1,
	field2,
	...,
	field 
FROM
	tablename1
	LEFT JOIN tablename2 ON tablename1.id = tablename2.id
```

**关于连接方式：** 参考：https://www.zsythink.net/archives/1105

分为：`cross join， inner join，left join，right join，union，union all，full join。 ` 

#####  排序： #####

按照 `field1` 进行排序。

```sql
SELECT
	field1,
	field2,
	...,
	field 
FROM
	tablename 
ORDER BY
	field1
```

查询表格中第二大的数据。

```sql
SELECT
	max( Salary ) AS SecondHighestSalary 
FROM
	Employee 
WHERE
	Salary < (
	SELECT
		max( Salary ) 
FROM
	Employee)
```

```sql
SELECT
	IFNULL( ( SELECT DISTINCT Salary FROM Employee ORDER BY Salary DESC LIMIT 1 OFFSET 1 ), NULL ) AS SecondHighestSalary
```

**MySQL中编写函数：**

```sql
create function 函数名([参数列表]) returns 数据类型
begin
 sql语句;
 return 值;
end;
```

```sql
CREATE FUNCTION getNthHighestSalary(N INT) RETURNS INT
BEGIN
    SET N = N - 1;
  RETURN (
      # Write your MySQL query statement below.
      SELECT
	    IFNULL( ( SELECT DISTINCT Salary FROM Employee ORDER BY Salary DESC LIMIT N, 1 ), NULL ) AS SecondHighestSalary
  );
END
```

**注意 `limit` 和 `limit offset` 使用的区别。**

`limit` ：含义是跳过2条取出1条数据，limit后面是从第2条开始读，读取1条信息，即读取第3条数据。

`limit offset` ：含义是从第1条（不包括）数据开始取出2条数据，limit后面跟的是2条数据，offset后面是从第1条开始读取，即读取第2,3条。

**判断一条记录是否在MySQL中已经存在：**可以选一个或者几个有代表性的字段，让需要写入数据库的数据等于这几个字段，看是否可以查询出记录。如果只在乎是否有重复，在查询的时候使用LIMIT 1限制显示一条，可以提升查询速度。

**MySQL中索引的创建：**主键默认已经创建了索引。

```sql
create index [index_name] on [tablename](column_name) # 创建索引。
drop index [index_name] on [tablename] # 删除索引
SELECT * FROM mysql.`innodb_index_stats` a WHERE a.`database_name` = '数据库名'; # 查看数据库中已经存在的索引。
```

----

### 使用Python操作MySQL：

##### 查询数据： #####

```python
def creatr_thing():
    try:
        db = pymysql.connect(host='localhost', user='root', password='password', database='world')
        db.autocommit(True)
        db_curs = db.cursor()
        print('连接成功...')
        sql_ = "select * from city\
                where CountryCode='NLD'"
        db_curs.execute(sql_)
        result = db_curs.fetchall()
        print(type(result))
        for i in result:
            print(type(i))
            print(i)
    except Exception as err:
        print(err)
```

查询到的结果为一个元组，元组套元组的格式。

##### 插入数据： #####

```python
class DyttPipeline(object):
    def process_item(self, item, spider):
        """
        因为有参数传入，并且在传入的参数为一个生成器，所以在每次得到一个结果的时候会先把结果存储到数据库中，循环往复。
        """
        # print(item["movie"])
        # print("*" * 100)
        # print(item)
        insert_data = [item["movie_date"], item["movie_name"], item["movie_url"]]
        print(insert_data)
        
        db = pymysql.connect(host="localhost", user="root", password="password", database="world")
        db_curs = db.cursor()
        insert_sql = """INSERT INTO dytt_1(movie_date, movie_name, movie_url) VALUES (%s, %s, %s);"""
        data = [insert_data]
        # print(data)
        try:
            db_curs.executemany(insert_sql, data)
            db.commit()
            print("ok")
        except:
            db.rollback()
            print("insert error")
        db_curs.close()
        print("This is a message")
        return item
    
```

在此段中，待写入数据库的格式可能不是很清楚，在数据外需要套一层中括号来为其增加索引的条件，否则会出现错误。如果设置了自增ID的话，不需要对ID进行赋值。



##### 查找 MySQL 中重复的数据： #####

```mysql
SELECT id, movie_url, COUNT(*) FROM dytt_1 GROUP BY movie_name HAVING COUNT(*) > 1
```

返回的结果是重复次数大于 1 的项目数。

##### 删除 MySQL 中重复的数据： #####

```mysql
DELETE 
FROM
	dytt_1 
WHERE
	movie_name IN (
SELECT
	t.movie_name 
FROM
	( SELECT movie_name FROM dytt_1 GROUP BY movie_name HAVING COUNT( * ) > 1 ) t ) 
AND id NOT IN (
SELECT
	dt.m
FROM
	( SELECT MIN( id ) AS m FROM dytt_1 GROUP BY movie_name HAVING COUNT( * ) > 1 ) dt 
	)
```

这样删除之后就会成为不重复的数据，但是 id 就会变得很跳跃，就已经不是连续的了。如果需要将 id 变为连续的，那么有一个办法就是将目前的数据写入到一个新的表中，将 id 设为自增，前提是要设置 id 为 `int` 类型。

##### **更改数据表的名称：**  #####

```sql
ALTER TABLE tablename1 RENAME TO tablename2;
```

##### **往 MySQL 中插入少量数据：**  #####

```sql
INSERT INTO databasename (field1, field2, ..., field) VALUES (field1, field2, ..., field)
```

**更新 SQL 中的少量数据：**

```sql
UPDATE databasename SET field1 = 'data1', field2 = 'data2', ..., field = 'data' WHERE id = n
```

##### **将一个表中的数据全部放到另外一个表中：**  #####

```sql
INSERT INTO tablename1 ( field1, field2, ..., field ) SELECT
field1,
field2,
.,
.,
.,
field 
FROM
	tablename2
```

tablename1 是要保存新数据的表，tablename2 是原表，需要这种操作一般是在原表删除数据之后，id 不连续增长，将其放在新表里面让 id 连续。在 tablename1 中的列名要和 tablename2 中的列名一一对应。**如果是需要从数据库A中的表添加数据到数据库B中的表，则需要在查询语句是添加数据库名，如`databasename.tablename`**。

### 存储过程： ###

*关于MySQL的存储过程： MySQL储存过程是一组为了完成特定功能的SQL语句集，经过编译之后存储在数据库中，当需要使用该组SQL语句时用户只需要通过指定储存过程的名字并给定参数就可以调用执行它了，简而言之就是一组已经写好的命令，需要使用的时候拿出来用就可以了。* 

MySQL存储过程是一个可编写的函数，在数据库中创建并保存，它可以有一些SQL语句和一些特殊的控制结构组成。数据库中的存储过程可以看做是编程中面向对象方法的模拟，允许控制数据的访问方式！

1.   能实现较快的执行速度。（存储过程是预编译的）
2.   存储过程允许的标准组件式编程。（封装起来可以多次调用）
3.   存储过程可以用流控制语句编写，有很强的灵活性，可以完成复杂的判断和较复杂的运算。
4.   存储过程可以被作为一种安全机制来利用。（设置相应数据的访问权限）
5.   存储过程可以减少网络流量。

##### **存储过程中的变量：**  #####

1.    DECLARE局部变量：` DECLARE var_name[,...] type [DEFAULT value] `，这个语句被用来声明局部变量，如果需要给变量设置一个默认值，需要使用DEFAULT字段，可以为一个表达式，如果没有DEFAULT，那默认值为NULL。作用范围为BEGIN....END内。
2.   **变量SET语句：` SET var_name = expr [, var_name = expr] `， 在存储程序中的SET语句是一般SET语句的扩展版本。  被参考变量可能是子程序内声明的变量，或者是全局服务器变量。 在存储程序中的SET语句作为预先存在的SET语法的一部分来实现。这允许SET a=x, b=y, ...这样的扩展语法。其中不同的变量类型（局域声明变量及全局和集体变量）可以被混合起来。这也允许把局部变量和一些只对系统变量有意义的选项合并起来。** 
3.   SELECT...INTO 语句：` SELECT col_name[,...] INTO var_name[,...] table_expr `。  这个SELECT语法把选定的列直接存储到变量。因此，只有单一的行可以被取回。 `SELECT id,data INTO x,y FROM test.t1 LIMIT 1; ` 

##### **存储过程结构：** #####

```sql
# 无参数的存储过程
CREATE PROCEDURE P()
BEGIN 
# 存储过程的正式语句
END
----------------------
CREATE PROCEDURE produceavg()
BEGIN
SELECT AVG(price) AS 平均价格 
FROM tablename;
END;
```

在BEGIN和END中间是存储过程的主体。调用的方法是 `CALL prodeceavg();`。

删除存储过程的方法是`DROP PROCEDURE produceavg;`。 

```sql
# 带参数的存储过程
CREATE PROCEDURE produceavg(
OUT p1 DECIMAL(8, 2)
OUT P2 DECIMAL(8, 2)
OUT p2 DECIMAL(8, 2)
)
BEGIN 
SELECT MIN(price) INTO p1 FROM tablename;
SELECT MAX(price) INTO p2 FROM tablename;
SELECT AVG(price) INTO p3 FROM tablename;
END;

```

`DECIMAL(8, 2)` 表示，十进制，整数位为8，小数位为2。OUT 表示参数来源来自存储过程中的输出。

其中包括，OUT, IN, INOUT。调用过程：

`CALL produceavg(@p1, @p2, @p3)`参数必须以@开头，获取参数的值，`SELECT @p1, @p2, @p3`。

**不能在一个存储过程中删除另一个存储过程，只能调用另外一个存储过程！**

```python
show procedure status # 显示数据库中所有存储过程的基本信息，包括所属数据库，名称和创建时间等。
show create proceduce sp_name # 显示某个存储过程的详细信息。
```

### 一些函数方法的用法： ###

常用基本函数：

参考： https://www.cnblogs.com/jiangxiaobo/p/7448854.html 

GROUP BY：按某一列分组，分组之后可以使用聚合函数，如MAX, MIN, AVG, SUM等对这个组别进行汇总操作。

ORDER BY：按照某一组进行排序，默认使用升序进行排列，ORDER BY DESC则为降序排列。

WHERE：条件语句，当某一条件成立时的结果。

LEFT JOIN...ON...：连接方法，上文有链接参考。

CEILING(*X*) CEIL(*X*)：返回一个不小于X的最小整数值。FLOOR(*X*)：返回不大于X的最大整数值。

DATE(expr)：提取日期时间表达式中的日期部分。'**2003-12-31 01:02:03**'，'**2003-12-31**'。DATE_FORMAT( )

CAST、CONVERT：类型转换函数，用法不同。CAST(expr AS type)、CONVERT(expr, type)





## 二、非关系型数据库  ##

关于 `Redis` 和 `MongoDB` 的区别：https://www.cnblogs.com/java-spring/p/9488227.html

### 1、`Redis`及配置   ###

内容： https://my.oschina.net/javagg/blog/471433 

`Redis`是一个开源的使用ANSI C语言编写、遵守BSD协议、支持网络、可基于内存亦可持久化的日志型、Key-Value数据库，并提供多种语言的API。 

它通常被称为数据结构服务器，因为值（value）可以是 字符串(String), 哈希(Hash), 列表(list), 集合(sets) 和 有序集合(sorted sets)等类型。

`Redis` 与其他 key - value 缓存产品有以下三个特点：

-   `Redis`支持数据的持久化，可以将内存中的数据保存在磁盘中，重启的时候可以再次加载进行使用。
-   `Redis`不仅仅支持简单的key-value类型的数据，同时还提供`list，set，zset，hash`等数据结构的存储。
-   `Redis`支持数据的备份，即master-slave模式的数据备份。

安装之后，在 `cmd` 命令行使用下面的命令运行 `redis` 服务。

```
redis-server.exe
```

默认的端口号为 6379。

关于 `Redis` 的管理工具，我使用的一个是 `Redis Desktop Manage` 另外一个是网页版的 `treesoft` 。个人觉得可以两个结合起来用，会比较方便。

关于`redis shell`： 

在`redis shell` 中的一些常用命令：

```python
redis-cli --raw;
set keyname keyvalue; # 键的类型为string。
shutdown;
get keyname;
----------------------
rpush/lpush listname value; # 列表数据的生成
lrange listname start end; # 查看数据。
----------------------
sadd setname value; # 集合的生成，集合中不存在完全相同的两个元素。
zadd 				# 有序集合。
smembers setname; # 列出集合中所有的值。
sismember setname value; # 判断一个值是否在集合中，存在返回1，不存在返回0.
sunion set1 set2; # 求两个集合的并集。
----------------------
HSET HashName value1 value2; # 建立一个哈希表
HGETALL HashName; # 哈希表中所有的数据。
# 关于更改Hash表中的数据。
```



**`Redis`的事物：** 

```python
MULTI: # 标记或组装一个事物，
EXEC: # 开始一个事物。
DISCARD: # 取消一个事物。
WATCH: # 用来监视一些key，一旦这些key在事物执行之前被改变，则取消事物的执行。
```

在事物执行之后，假如是写命令，那么会在AOF文件中一次性生成写的命令，将需要写入的数据一次写入。如果其中出现断电的情况可能会造成AOF文件不全的问题， 我们可以使用`redis-check-aof`工具来修复这一问题 ， 这个工具会将AOF文件中不完整的信息移除，确保AOF文件完整可用。

WATCH会监视key，包括多个key，一旦发现某个key被修改则会造成事物无法被执行的



在启动`redis` 服务之后，打开新的命令提示符窗口，输入`redis-cli --raw` 就可以进入到 shell 命令行了。输入`keys *` 可以得到所有的键的名称。`dbsize`可以得到键的个数。*但是目前存在一个问题，就是在`redis shell` 中输入中文会显示乱码的问题，并不是编码错误。* 

**`redis`持久化**：由于`redis`是内存型数据，当内存断电之后会丢失数据，所以为了保证数据不丢失需要进行持久化。

`RDB(Redis Database)`持久化：会将某个时间点的所有数据存放到硬盘上；可以将快照复制到其他服务器从而创建相同数据库的服务器副本；如果发生故障，将会丢失最后一次创建快照之后的数据；如果数据量比较大，保存快照的时间会比较长。

`AOF(Append Only File)`持久化：使用AOF持久化需要设置同步选项，从而确保写命令同步到磁盘上的时机。这是因为对文件进行写入操作并不会立即将内容同步到磁盘上，而是先到缓存区，然后由操作系统决定什么时候写入到磁盘中。有三个命令：

`always`：每个命令都同步（这个会严重降低服务器的性能，）；`everysec`：每秒都同步（如果系统发生崩溃，只是丢失一秒的数据，并且`Redis`每秒执行一次对服务器的影响也比较小）；`no`：让操作系统决定何时同步（对于服务器性能没有影响，然而系统崩溃是会丢失比较多的数据）。

***AOF在默认的 `redis.windows.conf`中是关闭的，具体在配置文件中显示的是：`appendonly no`，所以需要改变参数，将 no 改为 yes ，然后在目录下面会生成一个`appendonl.aof`文件。而且，RDB持久化和AOF持久化是不冲突的。*** 

 随着服务器写请求的增多，AOF 文件会越来越大。`Redis` 提供了一种将 AOF 重写的特性，能够去除 AOF 文件中的冗余写命令。参考： https://blog.csdn.net/hezhiqiang1314/article/details/69396887#aof-重写 

**两者的比较 ：**

1、AOF比RDB的频率高，优先使用AOF还原数据。

2、AOF比RDB的安全性也更大。

3、RDB的性能比AOF好。

4、如果两个都配置了，优先加载AOF。

`Redis`通讯协议RESP：是`Redis`中客户端和服务端的一种通讯方式。**特点：** 实现简单，快速解析，可读性好。

关于持久化方案，一般是两者都采用，这样可以最大程度的保证可靠性！



**主从用法：** 一般来讲，主服务器一边执行着数据的读写，一边进行着数据的持久化。在主架构中，可以关闭主服务的持久化功能，把持久化的功能放在从服务器上面，可以一定程度上提高主服务器的运行效率。而且主从是异步进行的，所以不会影响主逻辑，也基本不会影响`redis`的性能！

**主从同步原理：**SYNC指令表示同步主从服务器，当主服务器接受到指令之后，会调用BGSAVE指令来创建一个子进程来专门进行数据的持久化工作，将主服务器上的数据写入到RDB文件中。在持久化期间，所有的写命令都存在在缓存中。BGSAVE执行完成之后，主服务器会将持久化好的RDB文件发送到从服务器，从服务器将其存到磁盘，再读取到内存中。（可能存在主从断连的问题！）

 主服务器会在内存中维护一个缓冲区，缓冲区中存储着将要发给从服务器的内容。从服务器在与主服务器出现网络瞬断之后，从服务器会尝试再次与主服务器连接，一旦连接成功，从服务器就会把“希望同步的主服务器ID”和“希望请求的数据的偏移位置（replication offset）”发送出去。主服务器接收到这样的同步请求后，首先会验证主服务器ID是否和自己的ID匹配，其次会检查“请求的偏移位置”是否存在于自己的缓冲区中，如果两者都满足的话，主服务器就会向从服务器发送增量内容。 

**关于`redis`中的配置文件：**

 配置文件介绍：https://www.cnblogs.com/eastfu/p/8052239.html 

` daemonize no`：设置为`yes`的话会以守护进程的方式，采用单进程多线程，而且会一直在后台运行，除非手动kill掉这个进程。默认情况下是no，当退出命令行界面的时候`redis`的服务也会退出！

#### 使用 Python 操作 `Redis`   ####

```python
def operating_redis():
    """
    操作 Redis
    """
    try:
        pool = redis.ConnectionPool(host='localhost', port=6379, decode_responses=True)
        r = redis.Redis(connection_pool=pool)
        # 建立 redis 的连接池，对每次连接是不影响，设置decode_responses=True可以保证返回结果正常显示
        # print("连接成功...")
        movie_date = r.lrange('movie_date', 0, -1)
        movie_name = r.lrange('movie_name', 0, -1)
        movie_url = r.lrange('movie_url', 0, -1)

        movie_date_new = list(set(movie_date))
        movie_name_new = list(set(movie_name))
        movie_url_new = list(set(movie_url))

        write_in_redis('movie_date_new', movie_date_new)
        write_in_redis('movie_name_new', movie_name_new)
        write_in_redis('movie_url_new', movie_url_new)
    except Exception as err :
        print(err)
        

def write_in_redis(key_name: str, value: list):
    """
    上面函数的附加函数，写入数据库时调用。
    """
    pool = redis.ConnectionPool(host='localhost', port=6379, decode_responses=True)
    r = redis.Redis(connection_pool=pool)
    for l in value:
        r.sadd(key_name, l)
```

上面两个函数的作用是去除数据库中的重复数据。首先第一个函数建立连接池连接 `redis` 数据库，然后读取数据库中的数据，使用 `set()` 判断是否有重复数据，对比长度即可。然后将新的集合保存到新的变量，通过下面的函数逐一遍历写到 `redis` 中。

对于处理重复数据来讲，少量数据可能 `redis` 比较方便。在 MySQL 中删除重复数据之后 ID 就会变得不连续，所以需要将数据重新导入新表中。

#### `Redis` ####

##### 1、`Redis`中可以保存的数据类型？ #####

数据类型和结构。

##### 2、`Redis` 中的架构方式有哪些及其特点？ #####

单机、主从复制、哨兵模式、集群（proxy型）、集群（直连型）。

参考： https://blog.csdn.net/qq_35958788/article/details/82876266 

##### 3、`redis`的优化方法？ #####

参考： https://www.cnblogs.com/shoshana-kong/p/10770894.html 

---



### 2、MongoDB ###

关于 `MongoDB` 的学习：https://cuiqingcai.com/7121.html

官方文档（英文版）： https://docs.mongodb.com/manual/ 

MongoDB 是一个介于关系数据库和非关系数据库之间的产品，是非关系数据库当中功能最丰富，最像关系数据库的，MongoDB 是一个基于分布式文件存储的数据库。

关于分布式计算的优缺点可以参考 MongoDB 的教程。

**MongoDB 将数据存储为一个文档，数据结构由键值(key=>value)对组成。MongoDB 文档类似于 JSON 对象。字段值可以包含其他文档，数组及文档数组。**

在 MongoDB 中不支持表连接，而且 MongoDB 自动将 id 设为主键。

对于型数据库中每个表来讲，可以在MongoDB中转化成为一个个字典。同一个表中一行数据是一个字典。如下：

![image-20191116090415837](C:\Users\NaOH\AppData\Roaming\Typora\typora-user-images\image-20191116090415837.png)

---

最好找一个比较好的 MongoDB 管理工具，这里使用 Studio 3T，可以比较方便的管理 MongoDB，如果后面遇见更加方便的会结合起来使用。

使用 Studio 3T 可以比较方便的导入关系型数据的的数据进去，比如 MySQL。Studio 3T 中提供三种数据预览方式，一种是表格类型，一种是 JSON 格式，另外一种是树形，都比较直观。

***关于自建的 _id :*** *在文档中肯定存在一个这个键，类型可以是任何类型，默认是`ObjectID`对象，而且每个文档都有一个唯一的 _id ，确保文档能被唯一标识。这个键是按照插入数据的顺序生成的，以 16 进制的数据进行增长，就是从 0 - f ，f 完了之后进一位。* 

参考：https://www.cnblogs.com/weilunhui/p/6861938.html

##### **关于查询：** #####

```python
db.COLLECTION_NAME.find().pretty() # 格式化查询结果输出。
```

还包括在SQL中的where语句和比较操作符的使用。还有and语句和or语句，以及两者的联合使用。

参考： [http://www.bluestep.cc/demos/mongodb/manual/%E6%95%99%E7%A8%8B/10.html](http://www.bluestep.cc/demos/mongodb/manual/教程/10.html) 

在studio3T中，可以先使用结构化查询语句，也就是常用的SQL查询结果，然后在Query Code中转化成Mongo shell 的语句。更加方便直观！*值得注意的是存在 $type 操作符可以按照文档中的类型来查找。*

同样也可以进行排序操作`sort({"id":1})`， 1为升序排列，-1为降序排列。

索引：索引是特殊的数据结构，索引是对数据库表中一列或多列的值进行排序的一种结构。MongoDB使用`ensureIndex()`方法来创建索引，1为升序创建索引，-1为降序创建索引。这个方法可以接收多个字段，称作复合索引，也包括诸多的可选参数。

聚合函数：主要用于处理数据，包括最大最小值，平均数求和等。`aggregate()`方法使用聚合！最好配合GROUP BY一起使用。**管道：**在Unix和Linux中一般将前一个命令的输出作为下一个命令的参数的方法称为管道。

*MongoDB的复制是将数据同步在多个服务器的过程。复制提供了数据的冗余备份，并且在多个服务器上存储了数据的副本，提高了数据的可用性，也可以保证数据的安全性，复制还允许从硬件故障和服务中断中恢复数据。* 

```python
mongod --port "PORT" --dbpath "YOUR_DB_DATA_PATH" --replSet "REPLICA_SET_INSTANCE_NAME"
```

使用` db.isMaster()  `判断当前节点是否为主节点。同时，只有在主节点才能将已经启动的服务添加到副本集当中。MongoDB的副本集与我们常见的主从有所不同，主从在主机宕机后所有服务将停止，而副本集在主机宕机后，副本会接管主节点成为主节点，不会出现宕机的情况。

**分片集群结构：**分片满足MongoDB数据量大量增长的需求。当数据量足够大的时候，一台服务器不足以存储数据，但可以提供足够的读写吞吐量，这时候就可以将数据分割在多台机器上，使得数据库可以处理和存储更多的数据。

使用`mongodump`命令来备份数据库，`mongorerstore`用来恢复数据。

```python
mongodump -h dbhost -d dbname -o dbdirectory # 进行数据备份的命令
# 如果不使用参数，默认备份所有的数据，而且位置在C:\Users\用户名\dump目录下
mongorestore -h dbhost -d dbname --directoryperdb dbdirectory # 进行数据恢复
```

---

##### 服务监控： #####

关于监控MongoDB的运行情况，可以使用 `mongostat` 和 `mongotop` 命令来监控服务的运行情况。

使用 `mongostat` 的界面如下：

![image-20191116150700785](C:\Users\NaOH\AppData\Roaming\Typora\typora-user-images\image-20191116150700785.png)

`mongotop`如下：

![image-20191116150741689](C:\Users\NaOH\AppData\Roaming\Typora\typora-user-images\image-20191116150741689.png)

两者虽然都是监控服务，但是显示的详情是不一样的，根据具体情况选择合适的命令监控。

`mongotop 10` 设置等待时长，每隔10秒显示一次详细信息。

---

---

##### MongoDB基础及命令：  #####

在MongoDB中一些比较常用的命令，在进入 `shell` 之后(`cmd`窗口输入mongo)：前提是将MongoDB的安装目录已经添加到系统变量当中，否则就在安装目录启动`cmd`。在启动MongoDB的服务之后，会显示一些信息，比如`shell`的版本和服务的版本，连接地址及端口，通常连接日志会在系统的local数据库的start_log的集合中。可以另外开一个`cmd`窗口，也可以在启动服务的窗口输入命令！

```python
show dbs, db, use collection_name, # 一些简单的命令。
---------------------------------

```

有几个数据库是系统本来就有的(系统保留)：

admin： 从权限的角度来看，这是"root"数据库。要是将一个用户添加到这个数据库，这个用户自动继承所有数据库的权限。一些特定的服务器端命令也只能从这个数据库运行，比如列出所有的数据库或者关闭服务器。

local： 这个数据永远不会被复制，可以用来存储限于本地单台服务器的任意集合。

config： 当Mongo用于分片设置时，config数据库在内部使用，用于保存分片的相关信息。

---

**文档**相当于关系型数据库中的每一行数据。关于命名， .和$有特别的意义，只有在特定环境下才能使用， 以下划线"_"开头的键是保留的(不是严格要求的)。

**集合**相当于关系型数据库中的表。但是集合是无模式的，就是说在一个集合中的文档可以不同，包括键名和键的个数都可以不一样，都可以存在在一个集合中。

 **Capped collections** 就是固定大小的collection。 它比较适合于记录日志等类似的功能，但是要是使用这个集合的话必须显式创建一个这样的集合，而且还需要设置这个集合的大小，单位是字节(存储空间是提前分配好的)。

```python
db.createCollection("mycoll", {capped:true, size:100000})
# 数据库不允许删除，如果删除使用drop()命令，要再使用的话需要重新声明。
```

**元数据：** 元数据是一个预留空间，在对数据库或应用程序结构执行修改时，其内容可以由数据库自动更新。**元数据是系统中各类数据描述的集合，是执行详细的数据收集和数据分析的主要途径。** 

MongoDB中支持多种数据类型：

```python
string, integer, boolean, double, arrays, timestamp, object, null, symbol, date, code, re等。
```

---

MongoDB的数据库默认是没有密码的，在启动服务之后，直接进入`shell` 就可以使用命令操作MongoDB。

参考： [http://www.bluestep.cc/demos/mongodb/manual/%E6%95%99%E7%A8%8B/4.html](http://www.bluestep.cc/demos/mongodb/manual/教程/4.html)  有连接本地服务和远程服务的例子。包括参数说明！

**创建数据库：**不像关系型数据库，MongoDB创建数据库的过程比较简单，不需要设置字段、主键等操作，`use databasename` 在 `shell` 中直接选择要用的数据库（集合）名字，如果存在这个名字的集合那就使用这个集合，如果不存在那就会新建一个，而且在进入 `shell` 之后默认使用的是 `tese` 数据库。

使用`db.dropDatebase()` 命令来删除数据库，可以先使用`db`命令来查看目前使用的数据库是哪个，需要在当前使用的数据库下执行此命令。这个命令不会删除掉关联到数据库的用户，如果想要删除掉关联的用户，使用`dropAllUserFromDatabase`。

在MongoDB中写入数据，在集合中插入文档。`db.collection_name.insert()` 命令可以将文档插入到集合中， 相当于在一个表中添加了一行数据。（所有存储在集合中的数据都是BSON格式的，是一种类似JSON的一种二进制存储格式。）可以将需要写入的数据存储在一个变量当中，将这个变量当做参数传给插入命令。

更新数据：两种方法，`update` 和 `save` 。`update` 是更新部分数据或全部数据，`save` 方法是通过替换文档的方式更新数据。

删除文档：`remove()`方法用来删除文档，在删除之前最好使用`find()`查询一下结果是否正确。如果想删除所有数据，（同样第二个位置还是有一些参数`justOne`，` writeConcern `）

```python
db.col.remove({})
```

---

##### MongoDB高级 #####

**关系：**MongoDB的关系表现在多个文档之间逻辑上的相互联系，通过嵌入和引用来建立关系。常用的关系有1:1、1:N、N:1、N:N。和关系型数据库的表关系差不多，但是形式不同。

1.  嵌入式关系：以用户和地址举例，一个用户可以有多个地址。嵌入式关系就是说将地址信息作为一个字段放在用户文档里，然后将一个或者多个地址信息放在地址的字段里面。（缺点就是，当地址数据不断增加的时候，数据量会越来越大，读写速度会有影响）
2.  引用式关系：这种方法把用户文档和地址数据文档分开，通过引用文档的ID字段来建立关系。也就是说，用户文档中的地址字段的值是地址文档中的ID字段。通过读取这些用户地址的ID得到用户的详细地址。这个过程需要两次查询，第一次先查找用户地址的ID，第二步通过ID查找详细的信息。

**数据库引用：**`DBRefs`引用和手动引用。当一个文档从多个集合引用文档的时候使用`DBRefs`。

```python
{ $ref : , $id : , $db :  }	# 引用形式
# $ref：集合名称，$id：引用的id，$db：数据库名称，可选参数。
```

关于覆盖索引查询，1、查询中的所有属性是索引的一部分。2、所有查询到的属性值都在同一个索引中。意思就是，所需要查询的属性或者值恰好是创建的索引，这时候查询就会使用索引值，而不会调出文档，所以速度很快。

查询分析：查询分析可以确保我们建议的索引是否有效，是查询语句性能分析的重要工具。常用函数有`explain()`和`hint()`。在查询结果后面加上`.explain()`可以返回一个查询结果的详细信息，包括是否开启了索引，游标类型，查询结果返回的文档数，花费的时间等。在一些特殊情况下也可以使用`hint()`来让MongoDB使用一个索引，有些情况下是可以提升性能的！

MongoDB不支持事物，所以不能过分的要求数据的完整性，但是操作几乎都是原子性的，也就是说，操作一个文档，保存、修改、删除等，要么完成，要么不完成。通过`.findAndModify()`方法可以用来构建一个工作队列。其中存在较多的参数， https://docs.mongodb.com/manual/reference/method/db.collection.findAndModify/ 官方文档。

高级索引：通过对子文档和子数组建立索引。对于子文档建立索引需要对子文档中的每个字段建立索引，但是对于子数组的话就不需要为数组中的每个元素创建索引，系统会自己创建。

索引限制：每建立一个索引都会消耗一定的内存空间，在对集合进行操作的时候也会使用索引，所以如果操作的数据量比较小，尽量还会不要使用索引。而且，由于索引占用的是RAM，所以应该在RAM的内存限制之内。尽量多的使用`explain()`来查看是否启用了索引查询。需要注意的是，集合中的索引不能超过64个，索引名的长度不能超过125个字符，一个复合索引最多可以有31个字段。

**关于`objectID`**，在MongoDB中每个文档都有一个唯一的_id，保证每个文档都能被唯一的标识。通过使用`getTimestamp()`来获取文档的创建之间。使用`new Objectid.str` 可以将 _id 转成字符串。

**Map Reduce：**这是一种计算模型，将大批量的工作分解执行。在不会使用分布式的情况下将程序运行在分布式的模式下。

```python
db.collection.mapReduce(
	function(){emit(key, value);}, # map函数
    function(key, values){retuen reduceFuction}, # Reduce函数
    {
        out:collection,
        query:document,
        sort:document,
        limit:nmber
    }
)
```

Map函数调用emit(key, value)，遍历collection中的所有记录，将key和value传递给Reduce函数进行处理。而且Map 函数必须调用 emit(key, value) 返回键值对。 Map 是映射函数， Reduce是统计函数，最下面的大括号中时函数的参数。（详细待补充！）

全文检索：全文索引对每个词建立一个索引，指明该词在文章中出现的次数和位置，当用户查询的时候，检索程序就根据事先建立的索引进行查找，并将查找的结果反馈给用户的检索方式。过程类似于通过字典中的检索字表查字的过程。 MongoDB 在 2.6 版本以后是默认开启全文检索的 。*创建全文索引：*暂不支持中文的全文索引。

```python
ensureIndex() # 创建全文索引，
getIndexes() # 获取索引名，
dropIndex() # 删除索引。
```

MongoDB正则表达式：使用  `$regex`  来操作和设置匹配字符串的正则表达式。如果不需要区分大小写，那么可以设置`  $options 为 $i `。需要注意的是要先使用eval对组合的字符串进行转换，否则就会出现不报错，但是返回值为空的情况！

 GridFS可以很好的存储大于16M的文件，它会将大的对象文件分割成多个chunk（文件片段），一般为256k每个，每个chunk将作为MongoDB的一个文档被存储在chunks集合中。 GridFS 用两个集合来存储一个文件：fs.files与fs.chunks。 在使用GridFS存储文件的时候，要先调用安装目录下bin的mongofile.exe工具。使用

```python
mongofiles.exe -d gridfs put filename # 将filename文件存储到MongoDB中，
db.fs.chunks.find({files_id:ObjectId('filename_objectid')}) #
```

将文件存储到MongoDB中，存储文档之后会返回一个文档。需要查看的时候使用第二个命令，然后会返回相应的文档数目，根据filename文件的大小返回的文档数目也是不一样的。

**固定集合：**在上文中的Capped Collections有介绍过。可以看作为一个环形队列，当集合空间用完之后，在插入的元素就会覆盖掉最开始插入的数据！

```python
db.cappedLogCollection.isCapped() # 判断集合是否为固定集合。
db.runCommand({"convertToCapped":"posts",size:10000}) # 将已经存在的集合转化为固定集合。
```

**MongoDB自动增长：**



---



Python连接到MongoDB：









**使用 Python 连接 MongoDB：** 

```python
def operating_mongodb():
    try:
        myclinent = pymongo.MongoClient('localhost', 27017)
        mydb = myclinent.dytt_movie	# 连接到数据库(集合)
        result_data = mydb.test	# 连接到数据库中的集合
        for i in result_data.find(): 
            print(i)	# 查找集合中的每个数据，并输出。
        one_result = result_data.find_one({'id': 1})
        print(one_result)
        print(type(one_result))	#查看单条结果的数据类型。
    except Exception as err:
        print(err)
```

首先在命令行窗口安装 `pymongo` 模块。

```python
pip3 install pymongo 
```

然后输入地址和端口号进行连接。

```python
 def creat_collections():   
    try:
        myclient = pymongo.MongoClient('localhost', 27017)
        mydb = myclient.world   # 不存在会新建一个数据库
        result = mydb.dytt_mongodb  # 不存在的话也会新建一个集合
        result.insert({'movie_name': item['movie_name'],
        'movie_date': item['movie_date'], 'movie_url': item['movie_url']})
        print('ok')
    except Exception as err:
        print(err)
```

如果连接的数据库不存在则会默认新建一个，需要查询的集合如果也不存在，那么也会新建一个集合。

**MongoDB 文档 CRUD 操作：** 

插入操作：

`db.collection.insertOne()`：将单个文档插入集合。

`db.collection.insertMany()`：多个文档插入集合。

`db.collection.insert()`：单个或者多个插入集合。

---



### 3、关系型数据库和非关系型数据库的区别。 ###

实际上来讲，只是用不同的方法来实现同一件事情。从以下几个方面来简单说明以下两者的区别！以MySQL和MongoDB为例。

1.   两者的存储数据的方式是不一样的，MySQL是以一种二维表的方式。MongoDB是以文档的方式，相同类型的文档存在一个集合中。MySQL中存在表结构，包括表名，字段名和字段数据类型。
2.   两者的事物也是有区别的，MySQL中保持ACID原则，原子性、一致性、独立性、持久性！但是在MongoDB中只有原子性。在MongoDB4.0中引入了事物的功能，用户需要创建一个接口session、然后再session中开始和提交事物。
3.   MySQL需要创建表和字段才能存储数据，MongoDB不需要创建表。MySQL需要保证数据完整性，实体完整性，域完整性，参照完整性，用户自定义完整性！
4.   两者的语句和查询方式不同，MySQL使用结构化查询语言，MongoDB有自己的查询方式。
5.   MySQL的读写性能不如MongoDB。两者的应用方面不一样。

